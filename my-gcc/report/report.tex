\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage{amsfonts}
\usepackage[margin=0.9in]{geometry}
\usepackage{algorithmicx}
\usepackage{algpseudocode}


\begin{document}
\title{Project Report: MyGCC}
%\subtitle{MyGCC: A basic C compiler}
\author{Ben Hadj Yahia Elyas\\Herbert Ryan\\Hofer Ludovic}
%\institution{University of Bordeaux 1 Science and Technology}

\maketitle
\newpage
\begin{abstract}
This document describes the work accomplished in the context of our undergraduate projet for the IN6012 course. The aim of the project was to implement a basic C compiler using multiple parsing tools.
One of the main goals was to be compatible with GCC, ie. to be able to generate code for the same target language (X86 AT\&T syntax), following the same standards as GCC.
The report focuses primarily on the tasks handled, work environment, successes and shortcomings that we encountered throughout the project.
\end{abstract}

\vspace{2cm}
\tableofcontents
\newpage 

\section{Accomplished Tasks}
The following is a list of the implemented functionalities:
\begin{itemize}
\item JFlex scanner.
\item CUP parser.
\item Syntax error management.
\item Compatibility mode for both 32 and 64 bits architectures.
\item Optimised computation of numeric-only expressions.
\item Dynamic allocation of stack frame.
\item Register manager, Label manager and String manager.
\item Elimination of unreachable code.
\end{itemize}

The following is a list of the handled C features:
\begin{itemize}
\item Arithmetic operations.
\item Binary comparisons.
\item Parentheses and priority management.
\item IF,ELSE and WHILE blocks.
\item Function calls and recursion.
\item Array type handling.
\item Handling of printf().
\item Special function: read\_int(n) (equivalent to scanf).
\end{itemize}


\section{Collaborative Work}
It may seem trivial, but communication was absolutely the key for working efficiently on our project. Through constant emailing and frequent meetings, we were always in touch and up to date regarding the project status.\\
Our first step was to study thoroughly the subject, in order to set up a proper and structured implementation.
We then established an SVN repository\footnote{http://code.google.com/p/my-c-compiler/} in order to get started as soon as possible.

\section{Scanner}
Our lexical scanner was implemented using JFlex\footnote{http://jflex.de/}, which turned out to be quite efficient and easy to use. The scanner generates and collects tokens based on the declared regular expressions. These tokens are then passed to the parser in order to begin the parsing phase.

\section{Parser}
The parser was implemented using CUP\footnote{http://www2.cs.tum.edu/projects/cup/}. The role of the parser is to reduce the sequence of tokens collected by the scanner, in order to determine its grammatical structure with respect to a formal grammar.\\
The first version of the grammar (as suggested in the project details) needed a lot of changes. One of the main issues was the shift/reduce errors because the grammar was ambiguous. This problem turned out to be very delicate when handling a declaration of a function and the function itself. This was solved by decomposing the ambiguous rules into several nested non-terminal rules.

\section{Code Generator}
The CodeGenerator.java is the main backbone of our compiler. Whenever a grammar rule is reduced, we push the necessary informations into the code generator stack. That way, we can retrieve the data and process it accordingly. The advantage of this method is that we can externalize the data (instead of accumulating it in the CUP file during the parse phase), which gives us a lot more possibilities (such as error management and code optimization).


Implementing our own stack while knowing that CUP already provides one might be an arguable decision, but it seemed appropriate for several reasons. The main reason is that using the CUP stack would make the handling of erroneous identifiers much more complex. Furthermore, following our modifications on the grammar, several similar tasks were repeated in different rules. In order to factorize the code (and to remain in an object-oriented perspective), it seemed that it would be quite useful to have a generic mechanism capable of handling several rules at once.\\

The functioning of the code generator is relatively simple. It's stack is supplied by the parser, which alerts the code generator about how to process the collected data. For instance, it could tell the code generator to perceive the data as a prototype or as a function.\\
Once the parsing is complete, the code generator will take charge of producing assembly code corresponding to the collected data. If no errors are detected, the code will be written in the destination file.


\section{Context}
One of the fundamental notions of compiling is the variables scope. Not knowing how far we could go, we have decided to go beyond global variables and variables local to a function. We have anticipated to be able to have declarations within a logical block or a loop, for example.\\
To solve this issue, we have implemented Context objects, that contain declarations, as well as a link to their parent. This would allow us to manage nested blocks. Unfortunately, we did not have the time to modify the grammar in order to be able to have declarations beyond the beginning of a function.


\section{Register Manager}
At the start of the project, we decided that it would be useful to have a register manager that would serve us to get a free register, or get the register in which we've loaded a certain variable.\\
But it turns out that it was far too complex to manage (for instance, when all registers are used, based on what criteria should we free a register?), and that it wasn't needed for expression handling, because only two registers are enough for this operation.\\
The register manager turned out to be useful for retrieving registers for a function call. Note that when more than 6 parameters are needed, we would pass the rest of the parameters on the stack.

\section{Expression handling}
One of the major challenges encountered was the correct handling of expressions.
The expressions were implemented using a binary tree structure. In order to process correctly an expression, we had to explore the tree for priorities (namely parentheses and higher precedences). The generalization of the algorithm is as follows:

\begin{algorithmic}
\State $handle(left\_child)$
\If{$right\_child \neq null$}
\State $push(result(left\_child))$
\State $handle(right\_child)$
\State $pop()$
\State $compute\_results()$
\EndIf
\end{algorithmic}

Note that the result will always be stored in EAX at the end of the execution.

\subsection{Numeric expressions}
We have implemented a slight optimization for our compiler: when evaluating expressions, we have noticed that GCC optimizes its computation if the expression is entirely numeric. For example, the instruction \emph{((5-1)*10)+2} will be immediately evaluated to \emph{42}, and won't go through the usual handling algorithm.

\section{Building and Testing}
In order to build the project, we have set up an Ant build. This build will setup a proper building environment.\\
In order to automate the process, we developed a script that would ensure the building process, as well as the project's integrity. The script enabled us to measure our work progress by launching it with a test module.\\
The test module allowed us to verify the consistency of the implemented functionalities throughout the different revisions. The tests became more and more complex as the project progressed.

\section{Debugging}
One of the greatest challenges we have encountered during this project was the huge diversity of errors. As opposed to our previous projects, where almost all of the errors were from a single language, we had the pleasure of enjoying multiple sources of errors.\\

\begin{itemize}
\item Scanner-related errors: erroneous regular expressions, Java errors.
\item Parser-related errors: shift/reduce conflicts, incorrect data transmission to the CodeGenerator, etc...
\item Java-related errors.
\item Errors in our C test files.
\item Errors in the produced assembly code.
\item Errors in the build files (Ant).
\item Erros in the test scripts.
\end{itemize}

Some of these errors were easily traceable (namely a compilation failure), while some others were very mysterious. When the execution of the generated code did not meet our expectations, we had to explore all the aspects of the project in order to determine the source of the problem. Thankfully we had access to GDB and Valgrind, which came a long way in helping us debugging critical sections.\\


\section{Error Management}
Unless you are Linus Torvalds, compiling errors are inevitable due to our human nature. We currently detect 3 types of errors:

\begin{itemize}
\item Lexical errors, such as illegal characters.
\item Parsing errors, when encountering a parsing issue.
\item Syntax errors, when there is an undefined variable, or an undefined reference to a function.
\end{itemize}

When encountering any type of error, the compiler will issue an error message, and abort the code generation phase. Note that the parser will continue the parsing phase and will detect further errors.

\section{Extensions}
In the near future, we intend to add a few more functionalities to MyGCC.\\
These features include:

\begin{itemize}
\item Static key-word.
\item Pointers.
\item Proper function calls with over 6 parameters.
\item Increment operators.
\end{itemize}

\section{Conclusion}
This project turned out to be far more complex than any of the previous projects, but it was also quite rewarding, since we had the chance to encounter some difficult situations. All of the programming notions we have studied at university were omnipresent in this project. From architecture, to C language, to object-oriented paradigm, syntax analysis was definitely not the only skill required for this task.\\

We realised that one of the toughest criterias of a good compiler, is to be 100\% reliable.
We have learned from our past projects that thorough organisation was primordial, which helped us get a good start on the project. But that still did not prevent us from commiting a few mistakes\footnote{Such as the lack of commentary, and the last-minute report}.\\

We are now even more aware about the benefits of team work, since mutual aid prevented us from wasting hours on certain problems. We took advantage of our personal experiences, while keeping in mind the final goal.


\end{document}
