\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage{amsfonts}
\usepackage[margin=0.9in]{geometry}


\begin{document}
\title{Project Report: MyGCC}
\author{Ben Hadj Yahia Elyas\\Herbert Ryan\\Hofer Ludovic}

\maketitle
\newpage
\begin{abstract}
This document describes the work accomplished in the context of our undergraduate projet for the IN6012 course. The aim of the project was to implement a basic C compiler using multiple parsing tools.
One of the main goals was to be compatible with GCC, ie. to be able to generate code for the same target language (X86 AT\&T syntax), following the same standards as GCC.
The report focuses primarily on the tasks handled, work environment, successes and shortcomings that we encountered throughout the project.
\end{abstract}
\vspace{2cm}
\tableofcontents
\newpage 

\section{Accomplished Tasks}
The following is a list of the implemented functionalities:
\begin{itemize}
\item JFlex scanner.
\item CUP parser.
\item Syntax error management.
\item Compatibility mode for both 32 and 64 bits architectures.
\item Optimised computation of numeric-only expressions.
\item Dynamic allocation of stack frame.
\item Register manager, Label manager and String manager.
\item Elimination of unreachable code.
\end{itemize}

The following is a list of the handled C features:
\begin{itemize}
\item Arithmetic operations.
\item Binary comparisons.
\item Parentheses and priority management.
\item IF,ELSE and WHILE blocks.
\item Function calls and recursion.
\item Array type handling.
\item Handling of printf().
\item Special function: read\_int(n) (equivalent to scanf).
\end{itemize}


\section{Collaborative Work}
It may seem trivial, but communication was absolutely the key for working efficiently on our project. Through constant emailing and frequent meetings, we were always in touch and up to date regarding the project's status.\\
Our first step was to study thoroughly the subject, in order to set up a proper and structured implementation.
We then established an SVN repository\footnote{http://code.google.com/p/my-c-compiler/} in order to get started as soon as possible.

\section{Scanner}
Our lexical scanner was implemented using JFlex\footnote{http://jflex.de/}, which turned out to be quite efficient and easy to use. The scanner generates and collects tokens based on the declared regular expressions. These tokens are then passed to the parser in order to begin the parsing phase.

\section{Parser}
The parser was implemented using CUP\footnote{http://www2.cs.tum.edu/projects/cup/}. The role of the parser is to reduce the sequence of tokens collected by the scanner, in order to determine its grammatical structure with respect to a formal grammar.\\
The first version of the grammar (as suggested in the project details) needed a lot of changes. One of the main issues was the shift/reduce errors because the grammar was ambiguous. This problem was very delicate when handling a declaration of a function and the function
itself. This was solved by resorting to a pseudo-Chomsky normal form approach.

\section{Code Generator}
The CodeGenerator.java is the main backbone of our compiler. Whenever a grammar rule is reduced, we push the necessary informations into the CodeGenerator stack. That way, we can retrieve the data and process it accordingly. The advantage of this method is that we can externalize the data (instead of accumulating it in the CUP file during the parse phase), which gives us a lot more possibilities (such as error management and code optimization).\\
Implémenter notre propre pile alors que cup en fournit une était un choix discutable, mais il nous a paru judicieux pour plusieurs raisons. La principale étant qu'une gestion trop basée sur le cup nous semblait rendre beaucoup plus complexe la gestion des identifiants incorrect. De plus, suite aux modifications effectuées sur notre grammaire, de nombreuses tâches similaires étaient répétées dans différentes règles. Afin de factoriser notre code, et en restant axé sur une optique programmation objet, il nous a semblé très intéressant d'avoir un méchanisme assez générique capable de traiter plusieurs règles d'un coup.\\
Le fonctionnement du générateur de code est relativement simple, sa pile est alimentée par le parser, qui signale dès qu'il le peut ce que le générateur doit faire des informations reçues. Il pourra par exemple demander à ce que le code générateur assimile les informations comme un prototype ou comme une fonction. Une fois le travail du parser terminé, le générateur de code va transformer toutes les informations reçues en code assembleur, et si aucune erreur n'est détectée, le code sera écrit dans le fichier de destination.

\section{Context}
Une des notions essentielle pour la compilation est la portée des variables. Ne sachant pas jusqu'où nous pourrions développer notre compilateur, nous avons décidé de ne pas nous contenter d'avoir des variables globales et des variables locales à la fonction, mais nous avons prévu de pouvoir avoir des déclarations à l'intérieur de blocs logiques ou de boucles par exemple. Pour résoudre ce problème, nous avons choisi d'utiliser des objets Context, qui comportent des déclarations, ainsi qu'un lien vers leur parent, cela permet de gérer des blocs avec un niveau d'imbrication très élevé. Malheureusement, nous n'avons pas eu le temps de faire évoluer notre grammaire et les déclarations ne sont donc toujours possibles qu'au début des fonctions.

\section{Register Manager}
TODO

\section{Expression handling}
One of the major challenges encountered was the correct handling of expressions.
The expressions were implemented using a binary tree structure. In order to process correctly an expression, we had to explore the tree for priorities (namely parentheses and higher precedences). The generalization of the algorithm is as follows:

\begin{enumerate}
\item handle left child
\item if (right child not null)\{
\item   push left child's result
\item   handle right child
\item   pop
\item   compute the two results
\item \}
\end{enumerate}

Note that the result will always be stored in EAX at the end of the execution.

\section{Building and Testing}
In order to build the project, we have set up an Ant build. This build will setup a proper building environment.\\
In order to automate the process, we developed a script that would ensure the building process, as well as the project's integrity. The script enabled us to measure our work progress by launching it with a test module.\\
The test module allowed us to verify the consistency of the implemented functionalities throughout the different revisions. The tests became more and more complex as the project progressed.

\section{Debugging our project}
Dans ce projet, une des grande difficulté à laquelle nous avons du faire face est l'immense variété de nature des erreurs que nous avons rencontrées. Afin de pouvoir corriger nos erreurs, nous avons du nous adapter pour ne pas être totalement bloqués par un type d'erreur dans lequel nous étions néophytes.\\
Contrairement aux projets que nous avons effectué jusqu'ici où presque la totalité des erreurs étaient dans un seul langage, nous avions ici de nombreuses sources d'erreurs possible.\\
\begin{itemize}
\item Les erreurs provenant du scanner (expressions mal choisies, erreurs de code java)
\item Les erreurs provenant du parser (conflits shift/reduce, mauvais envois au CodeGenerator, etc..)
\item Les erreurs java
\item Les erreurs dans nos fichiers de test c
\item Les erreurs dans le code assembleur produit
\item Les erreurs dans notre fichier de build (ant)
\item Les erreurs dans nos scripts de tests
\end{itemize}
Si pour certaines de ces erreurs l'origine était facile à cerner (typiquement les erreurs donnant lieu à un échec de compilation), pour d'autres, nous nagions parfois dans le brouillard. Lorsque l'exécution du code produit ne correspondait pas à nos attentes, il nous a fallu plusieurs fois explorer toutes les différentes facettes du projet pour déterminer la source de l'erreur. Heureusement l'existence d'outils efficaces pour débuguer le code assembleur a pu nous sauver pour certains aspects assez critiques.\\
La grande variété des outils utilisés qui a introduit cette complexité de débogage était cependant nécessaire à la réalisation d'une tâche aussi complexe.

\section{Error Management}
Unless you are Linus Torvalds, compiling errors are inevitable due to our human nature. We currently detect 3 types of errors:

\begin{itemize}
\item Lexical errors, such as illegal characters.
\item Parsing errors, when encountering a parsing issue.
\item Syntax errors, when there is an undefined variable, or an undefined reference to a function.
\end{itemize}

When encountering any type of error, the compiler will issue an error message, and abort the code generation phase.

\section{Extensions}
In the near future, we intend to add a few more functionalities to MyGCC.\\
These features include:

\begin{itemize}
\item Static key-word.
\item Pointers.
\item Proper function calls with over 6 parameters.
\item Increment operators.
\end{itemize}

\end{document}
