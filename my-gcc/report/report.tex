\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage{amsfonts}
\usepackage[margin=0.9in]{geometry}


\begin{document}
\title{Project Report: MyGCC}
%\subtitle{MyGCC: A basic C compiler}
\author{Ben Hadj Yahia Elyas\\Herbert Ryan\\Hofer Ludovic}
%\institution{University of Bordeaux 1 Science and Technology}

\maketitle
\newpage
\begin{abstract}
This document describes the work accomplished in the context of our undergraduate projet for the IN6012 course. The aim of the project was to implement a basic C compiler using multiple parsing tools.
One of the main goals was to be compatible with GCC, ie. to be able to generate code for the same target language (X86 AT\&T syntax), following the same standards as GCC.
The report focuses primarily on the tasks handled, work environment, successes and shortcomings that we encountered throughout the project.
\end{abstract}

\vspace{2cm}
\tableofcontents
\newpage 

\section{Accomplished Tasks}
The following is a list of the implemented functionalities:
\begin{itemize}
\item JFlex scanner.
\item CUP parser.
\item Syntax error management.
\item Compatibility mode for both 32 and 64 bits architectures.
\item Optimised computation of numeric-only expressions.
\item Dynamic allocation of stack frame.
\item Register manager, Label manager and String manager.
\item Elimination of unreachable code.
\end{itemize}

The following is a list of the handled C features:
\begin{itemize}
\item Arithmetic operations.
\item Binary comparisons.
\item Parentheses and priority management.
\item IF,ELSE and WHILE blocks.
\item Function calls and recursion.
\item Array type handling.
\item Handling of printf().
\item Special function: read\_int(n) (equivalent to scanf).
\end{itemize}


\section{Collaborative Work}
It may seem trivial, but communication was absolutely the key for working efficiently on our project. Through constant emailing and frequent meetings, we were always in touch and up to date regarding the project status.\\
Our first step was to study thoroughly the subject, in order to set up a proper and structured implementation.
We then established an SVN repository\footnote{http://code.google.com/p/my-c-compiler/} in order to get started as soon as possible.

\section{Scanner}
Our lexical scanner was implemented using JFlex\footnote{http://jflex.de/}, which turned out to be quite efficient and easy to use. The scanner generates and collects tokens based on the declared regular expressions. These tokens are then passed to the parser in order to begin the parsing phase.

\section{Parser}
The parser was implemented using CUP\footnote{http://www2.cs.tum.edu/projects/cup/}. The role of the parser is to reduce the sequence of tokens collected by the scanner, in order to determine its grammatical structure with respect to a formal grammar.\\
The first version of the grammar (as suggested in the project details) needed a lot of changes. One of the main issues was the shift/reduce errors because the grammar was ambiguous. This problem turned out to be very delicate when handling a declaration of a function and the function itself. This was solved by decomposing the ambiguous rules into several nested non-terminal rules.

\section{Code Generator}
The CodeGenerator.java is the main backbone of our compiler. Whenever a grammar rule is reduced, we push the necessary informations into the code generator stack. That way, we can retrieve the data and process it accordingly. The advantage of this method is that we can externalize the data (instead of accumulating it in the CUP file during the parse phase), which gives us a lot more possibilities (such as error management and code optimization).


Implementing our own stack while knowing that CUP already provides one might be an arguable decision, but it seemed appropriate for several reasons. The main reason is that using the CUP stack would make the handling of erroneous identifiers much more complex. Furthermore, following our modifications on the grammar, several similar tasks were repeated in different rules. In order to factorize the code (and to remain in an object-oriented perspective), it seemed that it would be quite useful to have a generic mechanism capable of handling several rules at once.\\

The functioning of the code generator is relatively simple. It's stack is supplied by the parser, which alerts the code generator about how to process the collected data. For instance, it could tell the code generator to perceive the data as a prototype or as a function.\\
Once the parsing is complete, the code generator will take charge of producing assembly code corresponding to the collected data. If no errors are detected, the code will be written in the destination file.


\section{Context}
One of the fundamental notions of compiling is the variables scope. Not knowing how far we could go, we have decided to go beyond global variables and variables local to a function. We have anticipated to be able to have declarations within a logical block or a loop, for example.\\
To solve this issue, we have implemented Context objects, that contain declarations, as well as a link to their parent. This would allow us to manage nested blocks. Unfortunately, we did not have the time to modify the grammar in order to be able to have declarations beyond the beginning of a function.


\section{Register Manager}
TODO

\section{Expression handling}
One of the major challenges encountered was the correct handling of expressions.
The expressions were implemented using a binary tree structure. In order to process correctly an expression, we had to explore the tree for priorities (namely parentheses and higher precedences). The generalization of the algorithm is as follows:

\begin{enumerate}
\item handle left child
\item if (right child not null)\{
\item   push left child's result
\item   handle right child
\item   pop
\item   compute the two results
\item \}
\end{enumerate}

Note that the result will always be stored in EAX at the end of the execution.

\section{Building and Testing}
In order to build the project, we have set up an Ant build. This build will setup a proper building environment.\\
In order to automate the process, we developed a script that would ensure the building process, as well as the project's integrity. The script enabled us to measure our work progress by launching it with a test module.\\
The test module allowed us to verify the consistency of the implemented functionalities throughout the different revisions. The tests became more and more complex as the project progressed.

\section{Debugging}
One of the greatest challenges we have encountered during this project was the huge diversity of errors. As opposed to our previous projects, where almost all of the errors were from a single language, we had the pleasure of enjoying multiple sources of errors.\\

\begin{itemize}
\item Scanner-related errors: erroneous regular expressions, Java errors.
\item Parser-related errors: shift/reduce conflicts, incorrect data transmission to the CodeGenerator, etc...
\item Java-related errors.
\item Errors in our C test files.
\item Errors in the produced assembly code.
\item Errors in the build files (Ant).
\item Erros in the test scripts.
\end{itemize}

Some of these errors were easily traceable (namely a compilation failure), while some others were very mysterious. When the execution of the generated code did not meet our expectations, we had to explore all the aspects of the project in order to determine the source of the problem. Thankfully we had access to GDB and Valgrind, which came a long way in helping us debugging critical sections.\\


\section{Error Management}
Unless you are Linus Torvalds, compiling errors are inevitable due to our human nature. We currently detect 3 types of errors:

\begin{itemize}
\item Lexical errors, such as illegal characters.
\item Parsing errors, when encountering a parsing issue.
\item Syntax errors, when there is an undefined variable, or an undefined reference to a function.
\end{itemize}

When encountering any type of error, the compiler will issue an error message, and abort the code generation phase.

\section{Extensions}
In the near future, we intend to add a few more functionalities to MyGCC.\\
These features include:

\begin{itemize}
\item Static key-word.
\item Pointers.
\item Proper function calls with over 6 parameters.
\item Increment operators.
\end{itemize}

\section{Conclusion}
Ce travail de groupe a été bien plus complexe que tous ceux que nous avons fait en cours jusqu'à présent, mais il a aussi été très enrichissant en nous permettant de nous confronter à des difficultés qui dépassaient parfois ce qui avait été vu en cours. Toutes les notions de programmation que nous avons pu voir au cours de la licence y ont été réunies. De l'architecture au C, en passant par le langage objet, l'analyse syntaxique n'a de loin pas été la seule compétence nécessaire à la réalisation de ce travail.\\
Nous avons su tirer parti des enseignements de nos précédents projets en nous organisant plus rapidement et en nous répartissant le travail dès le début. Cela ne nous a pas pour autant empêché de faire de nombreuses erreurs\footnote{Par exemple, le manque de commentaires pendant l'écriture du code, le fait de rusher le rapport à la dernière minute} qui nous permettront de tirer de nouveaux enseignements pour la suite de notre parcours.\\
Nous avons pu aussi prendre conscience plus fortement de l'utilité du travail en groupe, l'entraide nous ayant plusieurs fois permis d'éviter de rester bloquer plusieurs heures sur certains bugs. Nous avons pu profité des spécialités de chacuns tout en gardant une vision globale du projet.

\end{document}
